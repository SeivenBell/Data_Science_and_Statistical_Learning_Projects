{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' class IonImageDatasetWithNormalizationTensors(Dataset):\\n\\n\\n\\n\\n\\n\\n\\n    def __init__(self, file_path):\\n\\n\\n\\n\\n\\n\\n\\n        # Load the .h5 file\\n\\n\\n\\n\\n\\n\\n\\n        self.file = h5py.File(file_path, \"r\")\\n\\n\\n\\n\\n\\n\\n\\n        # Extract and store keys\\n\\n\\n\\n\\n\\n\\n\\n        self.keys = list(self.file.keys())\\n\\n\\n\\n\\n\\n\\n\\n\\n        # Here, we compute the global mean and std using PyTorch tensors\\n\\n\\n\\n\\n\\n\\n\\n        self.global_mean, self.global_std = self.compute_global_mean_std()\\n\\n\\n\\n\\n\\n\\n\\n\\n    def compute_global_mean_std(self):\\n\\n\\n\\n\\n\\n\\n\\n        # Accumulators for mean and std computation\\n\\n\\n\\n\\n\\n\\n\\n        all_data = []\\n\\n\\n\\n\\n\\n\\n\\n        for key in self.keys:\\n\\n\\n\\n\\n\\n\\n\\n            data = torch.tensor(self.file[key][:], dtype=torch.float32).flatten()\\n\\n            all_data.append(data)\\n\\n\\n\\n\\n\\n\\n\\n        all_data = torch.cat(all_data)\\n\\n\\n\\n\\n\\n\\n\\n\\n        # Compute the global mean and std\\n\\n\\n\\n\\n\\n\\n\\n        global_mean = torch.mean(all_data)\\n\\n\\n\\n\\n\\n\\n\\n        global_std = torch.std(all_data)\\n\\n\\n\\n\\n\\n\\n\\n\\n        return global_mean.item(), global_std.item()\\n\\n\\n\\n\\n\\n\\n\\n\\n    def __len__(self):\\n\\n\\n\\n\\n\\n\\n\\n        return len(self.keys)\\n\\n\\n\\n\\n\\n\\n\\n\\n    def __getitem__(self, idx):\\n\\n\\n\\n\\n\\n\\n\\n        # Access the dataset using the key\\n\\n\\n\\n\\n\\n\\n\\n        data = self.file[self.keys[idx]]\\n\\n\\n\\n\\n\\n\\n\\n        # Convert the data to a torch tensor (for preprocessing)\\n\\n\\n\\n\\n\\n\\n\\n        image_tensor = torch.tensor(data[:], dtype=torch.float32)\\n\\n\\n\\n\\n\\n\\n\\n\\n        # Standardization\\n\\n\\n\\n\\n\\n\\n\\n        image_tensor = (image_tensor - self.global_mean) / self.global_std\\n\\n\\n\\n\\n\\n\\n\\n\\n        # Placeholder for actual label determination logic\\n\\n\\n\\n\\n\\n\\n\\n        label = torch.tensor(-1)\\n\\n\\n\\n\\n\\n\\n\\n\\n        return image_tensor, label\\n\\n\\n\\n\\n\\n\\n\\n\\n    def close(self):\\n\\n        self.file.close()\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n# Initialize the dataset with tensor-based normalization\\n\\n\\n\\n\\n\\n\\n\\ndataset_normalized_tensors = IonImageDatasetWithNormalizationTensors(file_path)\\n\\n\\n\\n\\n\\n\\n\\n\\n# Fetch one sample from the dataset to demonstrate normalization with tensors\\n\\n\\n\\n\\n\\n\\n\\nnormalized_tensor_sample_image, normalized_tensor_sample_label = (\\n\\n\\n\\n\\n\\n\\n\\n    dataset_normalized_tensors[2000]\\n\\n)\\n\\n\\n\\n\\n\\n\\n\\n\\n# Showing the shape of one sample image and its mean and std after normalization using tensors\\n\\nprint(\\n\\n    (\\n\\n\\n\\n\\n\\n\\n\\n        normalized_tensor_sample_image.shape,\\n\\n\\n\\n\\n\\n\\n\\n        normalized_tensor_sample_image.mean(),\\n\\n\\n\\n\\n\\n\\n\\n        normalized_tensor_sample_image.std(),\\n\\n\\n\\n\\n\\n\\n\\n        normalized_tensor_sample_label,\\n\\n    )\\n\\n)\\n\\n\\n\\n\\n\\n\\n\\n\\n# Remember to close the dataset file when done to avoid resource leaks\\n\\n\\n\\n\\n\\n\\n\\ndataset_normalized_tensors.close() '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\"\"\" class IonImageDatasetWithNormalizationTensors(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        # Load the .h5 file\n",
    "        self.file = h5py.File(file_path, \"r\")\n",
    "        # Extract and store keys\n",
    "        self.keys = list(self.file.keys())\n",
    "\n",
    "        # Here, we compute the global mean and std using PyTorch tensors\n",
    "        self.global_mean, self.global_std = self.compute_global_mean_std()\n",
    "\n",
    "    def compute_global_mean_std(self):\n",
    "        # Accumulators for mean and std computation\n",
    "        all_data = []\n",
    "        for key in self.keys:\n",
    "            data = torch.tensor(self.file[key][:], dtype=torch.float32).flatten()\n",
    "            all_data.append(data)\n",
    "        all_data = torch.cat(all_data)\n",
    "\n",
    "        # Compute the global mean and std\n",
    "        global_mean = torch.mean(all_data)\n",
    "        global_std = torch.std(all_data)\n",
    "\n",
    "        return global_mean.item(), global_std.item()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.keys)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Access the dataset using the key\n",
    "        data = self.file[self.keys[idx]]\n",
    "        # Convert the data to a torch tensor (for preprocessing)\n",
    "        image_tensor = torch.tensor(data[:], dtype=torch.float32)\n",
    "\n",
    "        # Standardization\n",
    "        image_tensor = (image_tensor - self.global_mean) / self.global_std\n",
    "\n",
    "        # Placeholder for actual label determination logic\n",
    "        label = torch.tensor(-1)\n",
    "\n",
    "        return image_tensor, label\n",
    "\n",
    "    def close(self):\n",
    "        self.file.close()\n",
    "\n",
    "\n",
    "# Initialize the dataset with tensor-based normalization\n",
    "dataset_normalized_tensors = IonImageDatasetWithNormalizationTensors(file_path)\n",
    "\n",
    "# Fetch one sample from the dataset to demonstrate normalization with tensors\n",
    "normalized_tensor_sample_image, normalized_tensor_sample_label = (\n",
    "    dataset_normalized_tensors[2000]\n",
    ")\n",
    "\n",
    "# Showing the shape of one sample image and its mean and std after normalization using tensors\n",
    "print(\n",
    "    (\n",
    "        normalized_tensor_sample_image.shape,\n",
    "        normalized_tensor_sample_image.mean(),\n",
    "        normalized_tensor_sample_image.std(),\n",
    "        normalized_tensor_sample_label,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Remember to close the dataset file when done to avoid resource leaks\n",
    "dataset_normalized_tensors.close() \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a convolutional neural network to classify images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py egg_info did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [15 lines of output]\n",
      "      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "      rather than 'sklearn' for pip commands.\n",
      "      \n",
      "      Here is how to fix this error in the main use cases:\n",
      "      - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "      - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "      - if the 'sklearn' package is used by one of your dependencies,\n",
      "        it would be great if you take some time to track which package uses\n",
      "        'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "      - as a last resort, set the environment variable\n",
      "        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "      \n",
      "      More information is available at\n",
      "      https://github.com/scikit-learn/sklearn-pypi-package\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "%pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (6400x128 and 32x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 114\u001b[0m\n\u001b[0;32m    111\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m--> 114\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, y_train\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# Backward and optimize\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Seiven\\anaconda3\\envs\\syde_522\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Seiven\\anaconda3\\envs\\syde_522\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[10], line 98\u001b[0m, in \u001b[0;36mCNNModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     96\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool1(x)\n\u001b[0;32m     97\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflatten(x)\n\u001b[1;32m---> 98\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu3(x)\n\u001b[0;32m    100\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x)\n",
      "File \u001b[1;32mc:\\Users\\Seiven\\anaconda3\\envs\\syde_522\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Seiven\\anaconda3\\envs\\syde_522\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Seiven\\anaconda3\\envs\\syde_522\\lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (6400x128 and 32x128)"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "# cropped_ions_file_path = \"binary/cropped_ions.h5\"\n",
    "\n",
    "labels_images_file_path = \"binary/labels_and_images.pt\"  # file path of .pt file\n",
    "tensor_data = torch.load(labels_images_file_path)\n",
    "images = tensor_data[\"images\"]\n",
    "labels = tensor_data[\"labels\"]\n",
    "\n",
    "# # Assuming you have the input image tensor and label tensor\n",
    "# images = # (10000, 4, 5, 5) tensor\n",
    "# labels = # (10000, 4, 1) tensor\n",
    "\n",
    "# Split the data into train, validation, and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    images, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Reshape the input tensor to have the correct shape\n",
    "X_train = X_train.view(-1, 4, 5, 5)\n",
    "X_val = X_val.view(-1, 4, 5, 5)\n",
    "X_test = X_test.view(-1, 4, 5, 5)\n",
    "\n",
    "# Reshape the label tensor to have the correct shape\n",
    "y_train = y_train.squeeze(-1).long()\n",
    "y_val = y_val.squeeze(-1).long()\n",
    "y_test = y_test.squeeze(-1).long()\n",
    "\n",
    "\n",
    "# # Define the CNN model\n",
    "# class CNNModel(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CNNModel, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(4, 32, kernel_size=2, stride=1, padding=1)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "#         self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "#         self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "#         self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "#         self.flatten = nn.Flatten()\n",
    "#         self.fc1 = nn.Linear(64 * 1 * 1, 128)\n",
    "#         self.relu3 = nn.ReLU()\n",
    "#         self.fc2 = nn.Linear(128, 4)\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.relu1(x)\n",
    "#         x = self.pool1(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = self.relu2(x)\n",
    "#         x = self.pool2(x)\n",
    "#         x = self.flatten(x)\n",
    "#         x = self.fc1(x)\n",
    "#         x = self.relu3(x)\n",
    "#         x = self.fc2(x)\n",
    "#         x = self.sigmoid(x)\n",
    "#         return x\n",
    "\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        # Only one convolutional layer without padding and with a kernel size of 2\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            4, 32, kernel_size=2, padding=0\n",
    "        )  # No padding, default stride=1\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Adjust the size in the Linear layer according to the output size from the pooling layer\n",
    "        # Note: The exact size calculation will depend on the input dimensions to the model\n",
    "        # Assuming the input dimensions are square and denoted as 'input_size', the calculation would be:\n",
    "        # output_size = (input_size - 1) / 2  # from conv1 and pool1\n",
    "        # output_size = output_size / 2  # additional pooling\n",
    "        # You will need to compute this based on your specific input dimensions and update the number '64' below\n",
    "        self.fc1 = nn.Linear(32 * 1 * 1, 128)  # Update the 'output_size' accordingly\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 4)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Create the model, optimizer, and loss function\n",
    "model = CNNModel()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 500\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train.float())\n",
    "\n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val)\n",
    "        val_loss = criterion(val_outputs, y_val.float())\n",
    "    print(\n",
    "        f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Validation Loss: {val_loss.item():.4f}\"\n",
    "    )\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test)\n",
    "    test_loss = criterion(test_outputs, y_test.float())\n",
    "    predicted = (test_outputs > 0.5).long()\n",
    "    test_accuracy = accuracy_score(y_test, predicted)\n",
    "    print(\n",
    "        f\"Test Loss: {test_loss.item():.4f}, Test Accuracy: {100 * test_accuracy:.2f}%\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "syde_522",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
