{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgGc4qaTjPrU"
      },
      "source": [
        "Welcome to aasignment 1.                                                       \n",
        "\n",
        "We are using pathology images for our first assignment please download data from this link https://drive.google.com/drive/folders/10dUOzcPR-PQwfFYcHk5gsLjIjSorQ32Q?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4s4K2S-dhTnF"
      },
      "source": [
        "\n",
        "\n",
        "# Task 1: Feature Generation (15%)\n",
        "# Use and run the following code (a deep network) to generate features from a set of training images. For this assignment, you do not need to know how the deep network is working here to extract features.\n",
        "# This code extracts the features of image T4.tif (in the T folder of dataset). Modify the code so that it iterates over all images of the dataset and extracts their features.\n",
        "# Allocate 10% of the data for validation.\n",
        "\n",
        "# Insert your code here for Task 1\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94c_H8Yv7IDs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import densenet121\n",
        "from torch.autograd import Variable\n",
        "from PIL import Image\n",
        "\n",
        "# Load pre-trained DenseNet model\n",
        "model = densenet121(pretrained=True)\n",
        "\n",
        "# Remove the classification layer (last fully connected layer)\n",
        "model = torch.nn.Sequential(*list(model.children())[:-1])\n",
        "\n",
        "# Add a global average pooling layer\n",
        "model.add_module('global_avg_pool', torch.nn.AdaptiveAvgPool2d(1))\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Define the image preprocessing pipeline\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Load an image\n",
        "image_path = \"T4.tif\"\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# Preprocess the image\n",
        "input_tensor = preprocess(image)\n",
        "input_batch = input_tensor.unsqueeze(0)  # Add a batch dimension\n",
        "\n",
        "# Wrap the input tensor in a Variable\n",
        "input_var = Variable(input_batch)\n",
        "\n",
        "# Forward pass through the model\n",
        "features = model(input_var)\n",
        "\n",
        "# Extract the feature tensor\n",
        "feature_vector = features.squeeze().detach().numpy()\n",
        "\n",
        "# Now 'feature_vector' contains the feature from the last fully connected layer of DenseNet\n",
        "print(\"Feature vector shape:\", feature_vector.shape)\n",
        "\n",
        "# Directory containing the data folder\n",
        "data_dir = \"train\"\n",
        "\n",
        "# List all directories\n",
        "directories = [folder for folder in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, folder))]\n",
        "\n",
        "# Initialize lists for storing images and labels\n",
        "images = []\n",
        "labels = []\n",
        "features = []\n",
        "\n",
        "# Loop through each directory\n",
        "for directory in directories:\n",
        "    folder_path = os.path.join(data_dir, directory)\n",
        "    if os.path.isdir(folder_path):\n",
        "        # List all files in the directory\n",
        "        files = os.listdir(folder_path)\n",
        "        # Filter out .tif files\n",
        "        tif_files = [file for file in files if file.endswith(\".tif\")]\n",
        "        # Load each .tif file\n",
        "        for file in tif_files:\n",
        "            image, feature_vector = extract_features(os.path.join(folder_path, file))\n",
        "            images.append(image)\n",
        "            # Append the label (folder name) to the list\n",
        "            labels.append(directory)\n",
        "            # Append feature vector\n",
        "            features.append(feature_vector)\n",
        "\n",
        "# Split paths and labels into train and validation sets\n",
        "train_features, val_features, train_labels, val_labels = train_test_split(features, labels, test_size=0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DguMbSShmHT"
      },
      "source": [
        "# Task 2: High Bias Classification Method (5%)\n",
        "# Choose a classification method and let is have a high bias.\n",
        "# Train it on the generated features and discuss why it is underfitting.\n",
        "\n",
        "# Insert your code here for Task 2\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xG7aIh1lhpW3"
      },
      "outputs": [],
      "source": [
        "# Use a multi-class logistic regression method to classify data\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# initialize a logistic regression model\n",
        "lr_model = LogisticRegression(max_iter=1000, multi_class='ovr')\n",
        "\n",
        "# perform k-fold cross validation\n",
        "k = 10\n",
        "lr_scores = cross_val_score(lr_model, train_features, train_labels, cv=k)\n",
        "\n",
        "# Print cross-validation scores for logistic regression\n",
        "for i, score in enumerate(lr_scores):\n",
        "    print(f\"Logistic Regression Fold {i+1} Accuracy: {score}\")\n",
        "\n",
        "# Print mean scores for logistic regression\n",
        "mean_lr_accuracy = np.mean(lr_scores)\n",
        "print(f\"Mean Logistic Regression Accuracy: {mean_lr_accuracy}\")\n",
        "\n",
        "# Use a multi-class SVM method to classify data\n",
        "hb_svm_model = svm.SVC(kernel='linear', C=0.01, gamma=1000)\n",
        "hb_svm_scores = cross_val_score(hb_svm_model, train_features, train_labels, cv=k)\n",
        "\n",
        "# Print the cross-validation scores\n",
        "for i, hb_score in enumerate(hb_svm_scores):\n",
        "    print(f\"SVM Fold {i+1} Accuracy: {hb_score}\")\n",
        "\n",
        "# Calculate and print the mean accuracy across all folds\n",
        "hb_mean_accuracy = np.mean(hb_svm_scores)\n",
        "print(f\"Mean SVM Accuracy: {hb_mean_accuracy}\")\n",
        "\n",
        "# Calculate and print the accuracy variance\n",
        "hb_accuracy_var = np.var(hb_svm_scores)n\",\n",
        "print(f\"SVM Accuracy Variance: {hb_accuracy_var}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kR8MxxoGhpxF"
      },
      "source": [
        "# Task 3: High Variance Classification Method (5%)\n",
        "# Use the chosen classification method and let it have a high variance.\n",
        "# Train it on the generated features and discuss why it is overfitting.\n",
        "\n",
        "# Insert your code here for Task 3\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrsSDN_7huYB"
      },
      "outputs": [],
      "source": [
        "# Use a multi-class SVM method to classify data\n",
        "hv_svm_model = svm.SVC(kernel='sigmoid')\n",
        "hv_svm_scores = cross_val_score(hv_svm_model, train_features, train_labels, cv=k)\n",
        "\n",
        "# Print the cross-validation scores\n",
        "for i, hv_score in enumerate(hv_svm_scores):\n",
        "    print(f\"SVM Fold {i+1} Accuracy: {hv_score}\")\n",
        "\n",
        "# Calculate and print the mean accuracy across all folds\n",
        "hv_mean_accuracy = np.mean(hv_svm_scores)\n",
        "print(f\"Mean SVM Accuracy: {hv_mean_accuracy}\")\n",
        "\n",
        "# Calculate and print the accuracy variance across all folds\n",
        "hv_accuracy_var = np.var(hv_svm_scores)\n",
        "print(f\"SVM Accuracy Variance: {hv_accuracy_var}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzxSVPWXht-m"
      },
      "source": [
        "# Task 4: Balanced Classification Method (15%)\n",
        "# Use the chosen classification method and let it balance the bias and variance.\n",
        "# Train it on the generated features, possibly adjusting parameters.\n",
        "# Discuss insights into achieving balance.\n",
        "\n",
        "# Insert your code here for Task 4\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjgmSxk7h7vZ"
      },
      "outputs": [],
      "source": [
        "balanced_svm_model = svm.SVC(kernel='linear')\n",
        "balanced_svm_scores = cross_val_score(balanced_svm_model, train_features, \n",
        "                                      train_labels, cv=k)\n",
        "\n",
        "# Print the cross-validation scores\n",
        "for i, balanced_score in enumerate(balanced_svm_scores):\n",
        "    print(f\"SVM Fold {i+1} Accuracy: {balanced_score}\")\n",
        "\n",
        "# Calculate and print the mean accuracy across all folds\n",
        "balanced_mean_accuracy = np.mean(balanced_svm_scores)\n",
        "print(f\"Balanced SVM Mean Accuracy: {balanced_mean_accuracy}\")\n",
        "\n",
        "# Calculate and print the accuracy variance across all folds\n",
        "balanced_accuracy_var = np.var(balanced_svm_scores)\n",
        "print(f\"Balanced SVM Accuracy Variance: {balanced_accuracy_var}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKRG3PfFh8Ot"
      },
      "source": [
        "# Task 5: K-Means Clustering (20%)\n",
        "# Apply K-Means clustering on the generated features.\n",
        "# Test with available labels and report accuracy.\n",
        "# Experiment with automated K and compare with manually set 20 clusters.\n",
        "\n",
        "# Insert your code here for Task 5\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLuOkJyAh-mN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43sPfI7Jh-9p"
      },
      "source": [
        "# Task 6: Additional Clustering Algorithm (10%)\n",
        "# Choose another clustering algorithm and apply it on the features.\n",
        "# Test accuracy with available labels.\n",
        "\n",
        "# Insert your code here for Task 6\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nn9f41LWiCDr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fPfoBsaiCXu"
      },
      "source": [
        "# Task 7: PCA for Classification Improvement (20%)\n",
        "# Apply PCA on the features and then feed them to the best classification method in the above tasks.\n",
        "# Assess if PCA improves outcomes and discuss the results.\n",
        "\n",
        "# Insert your code here for Task 7\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RoOFXhdmiHeD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQqNra7eiHx-"
      },
      "source": [
        "# Task 8: Visualization and Analysis (10%)\n",
        "# Plot the features in a lower dimension using dimentinality reduction techniques.\n",
        "# Analyze the visual representation, identifying patterns or insights.\n",
        "\n",
        "# Insert your code here for Task 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1npTL_NkjNdL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
