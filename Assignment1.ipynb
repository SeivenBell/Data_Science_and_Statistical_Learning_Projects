{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgGc4qaTjPrU"
      },
      "source": [
        "Welcome to assignment 1.                                                       \n",
        "\n",
        "We are using pathology images for our first assignment please download data from this link https://drive.google.com/drive/folders/10dUOzcPR-PQwfFYcHk5gsLjIjSorQ32Q?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4s4K2S-dhTnF"
      },
      "source": [
        "\n",
        "\n",
        "Task 1: Feature Generation (15%)\n",
        "Use and run the following code (a deep network) to generate features from a set of training images. For this assignment, you do not need to know how the deep network is working here to extract features.\n",
        "This code extracts the features of image T4.tif (in the T folder of dataset). Modify the code so that it iterates over all images of the dataset and extracts their features.\n",
        "Allocate 10% of the data for validation.\n",
        "\n",
        "Insert your code here for Task 1\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import the necessary packages\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import densenet121\n",
        "from torch.autograd import Variable\n",
        "from PIL import Image\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.metrics import silhouette_score\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "\n",
        "# imports for task 2\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "94c_H8Yv7IDs",
        "outputId": "8818abc2-2ac3-40a8-93c7-77f6514db44d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Features and labels for training, testing, and validation sets have been saved.\n"
          ]
        }
      ],
      "source": [
        "# Load the DenseNet model pre-trained on ImageNet\n",
        "model = densenet121(weights=True)\n",
        "# Modify the model to remove the last fully connected layer\n",
        "model = torch.nn.Sequential(*list(model.children())[:-1])\n",
        "# Add a global average pooling layer to the model\n",
        "model.add_module(\"global_avg_pool\", torch.nn.AdaptiveAvgPool2d(1))\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Define a series of transformations for preprocessing the images\n",
        "preprocess = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize(256),  # Resize the input images to 256x256\n",
        "        transforms.CenterCrop(224),  # Crop the images to 224x224\n",
        "        transforms.ToTensor(),  # Convert the images to PyTorch tensors\n",
        "        transforms.Normalize(\n",
        "            mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
        "        ),  # Normalize the images\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Specify the directory containing the dataset\n",
        "dataset_dir = \"train\"\n",
        "\n",
        "# Initialize lists to hold image paths and their corresponding labels\n",
        "image_paths = []\n",
        "labels = []\n",
        "\n",
        "# Iterate through each folder in the dataset directory\n",
        "for folder_name in os.listdir(dataset_dir):\n",
        "    folder_path = os.path.join(dataset_dir, folder_name)\n",
        "    # Check if the path is a directory\n",
        "    if os.path.isdir(folder_path):\n",
        "        # Iterate through each file in the folder\n",
        "        for file_name in os.listdir(folder_path):\n",
        "            # Check if the file is a TIFF image\n",
        "            if file_name.endswith(\".tif\"):\n",
        "                # Append the image path and label to their respective lists\n",
        "                image_paths.append(os.path.join(folder_path, file_name))\n",
        "                labels.append(folder_name)\n",
        "\n",
        "# Convert categorical labels into numeric labels\n",
        "unique_labels = sorted(set(labels))\n",
        "label_to_numeric = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "labels_numeric = [label_to_numeric[label] for label in labels]\n",
        "\n",
        "# Combine image paths and numeric labels into tuples for easy processing\n",
        "combined = list(zip(image_paths, labels_numeric))\n",
        "\n",
        "# Split the combined dataset into training/validation and testing sets\n",
        "train_val_combined, test_combined = train_test_split(\n",
        "    combined, test_size=0.1, random_state=42\n",
        ")\n",
        "\n",
        "# Further split the training/validation set into separate training and validation sets\n",
        "train_combined, val_combined = train_test_split(\n",
        "    train_val_combined, test_size=0.1, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "def extract_features_and_labels(combined_data):\n",
        "    \"\"\"\n",
        "    Extract features and labels from the given dataset.\n",
        "\n",
        "    Parameters:\n",
        "    - combined_data: A list of tuples, each containing the path to an image and its numeric label.\n",
        "\n",
        "    Returns:\n",
        "    - A tuple containing two numpy arrays: one for the extracted features and one for the corresponding labels.\n",
        "    \"\"\"\n",
        "    features = []\n",
        "    labels = []\n",
        "    for path, label in combined_data:\n",
        "        # Load the image from the specified path\n",
        "        image = Image.open(path)\n",
        "        # Preprocess the image\n",
        "        input_tensor = preprocess(image)\n",
        "        input_batch = input_tensor.unsqueeze(0)\n",
        "        # Extract features using the model\n",
        "        with torch.no_grad():\n",
        "            output = model(input_batch)\n",
        "        features.append(output.squeeze().detach().numpy())\n",
        "        labels.append(label)\n",
        "    return np.array(features), np.array(labels)\n",
        "\n",
        "\n",
        "# Extract features and labels for training, testing, and validation sets\n",
        "train_features, train_labels = extract_features_and_labels(train_combined)\n",
        "test_features, test_labels = extract_features_and_labels(test_combined)\n",
        "val_features, val_labels = extract_features_and_labels(val_combined)\n",
        "\n",
        "# Save the extracted features and labels to disk\n",
        "np.save(\"train_features.npy\", train_features)\n",
        "np.save(\"test_features.npy\", test_features)\n",
        "np.save(\"val_features.npy\", val_features)\n",
        "np.save(\"train_labels.npy\", train_labels)\n",
        "np.save(\"test_labels.npy\", test_labels)\n",
        "np.save(\"val_labels.npy\", val_labels)\n",
        "\n",
        "print(\"Features and labels for training, testing, and validation sets have been saved.\")\n",
        "\n",
        "# Note on fixing potential warning with updated model loading approach:\n",
        "# Uncomment and use the following code to address deprecation warnings related to loading pretrained models:\n",
        "# from torchvision.models import densenet121, DenseNet121_Weights\n",
        "# model_weights = DenseNet121_Weights.IMAGENET1K_V1  # Alternatively, use DenseNet121_Weights.DEFAULT for the latest weights\n",
        "# model = densenet121(weights=model_weights)\n",
        "# Modify the model similarly as above to prepare for feature extraction\n",
        "# model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DguMbSShmHT"
      },
      "source": [
        " Task 2: High Bias Classification Method (5%)\n",
        " Choose a classification method and let is have a high bias.\n",
        " Train it on the generated features and discuss why it is underfitting.\n",
        "\n",
        " Insert your code here for Task 2\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "xG7aIh1lhpW3",
        "outputId": "e254441d-2591-4163-ef74-1c884f3d5229"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression Fold 1 Accuracy: 1.0\n",
            "Logistic Regression Fold 2 Accuracy: 0.9523809523809523\n",
            "Logistic Regression Fold 3 Accuracy: 0.9841269841269841\n",
            "Logistic Regression Fold 4 Accuracy: 0.9523809523809523\n",
            "Logistic Regression Fold 5 Accuracy: 0.9841269841269841\n",
            "Logistic Regression Fold 6 Accuracy: 0.9841269841269841\n",
            "Logistic Regression Fold 7 Accuracy: 0.9682539682539683\n",
            "Logistic Regression Fold 8 Accuracy: 0.9841269841269841\n",
            "Logistic Regression Fold 9 Accuracy: 0.9523809523809523\n",
            "Logistic Regression Fold 10 Accuracy: 1.0\n",
            "Mean Logistic Regression Accuracy: 0.976190476190476\n",
            "0.16164817749603805 0.09859154929577464\n"
          ]
        }
      ],
      "source": [
        "# Use a multi-class logistic regression method to classify data\n",
        "# initialize a logistic regression model\n",
        "lr_model = LogisticRegression(max_iter=1000, multi_class=\"ovr\")\n",
        "\n",
        "# perform k-fold cross validation\n",
        "k = 10\n",
        "lr_scores = cross_val_score(lr_model, train_features, train_labels, cv=k)\n",
        "\n",
        "# Print cross-validation scores for logistic regression\n",
        "for i, score in enumerate(lr_scores):\n",
        "    print(f\"Logistic Regression Fold {i+1} Accuracy: {score}\")\n",
        "\n",
        "# Print mean scores for logistic regression\n",
        "mean_lr_accuracy = np.mean(lr_scores)\n",
        "print(f\"Mean Logistic Regression Accuracy: {mean_lr_accuracy}\")\n",
        "\n",
        "# Use a multi-class SVM method to classify data\n",
        "hb_svm_model = svm.SVC(kernel=\"linear\", C=0.00001, gamma=10000)\n",
        "hb_svm_model.fit(train_features, train_labels)\n",
        "hb_svm_train_score = hb_svm_model.score(\n",
        "    train_features, train_labels, sample_weight=None\n",
        ")\n",
        "hb_svm_val_score = hb_svm_model.score(val_features, val_labels, sample_weight=None)\n",
        "\n",
        "print(hb_svm_train_score, hb_svm_val_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kR8MxxoGhpxF"
      },
      "source": [
        " Task 3: High Variance Classification Method (5%)\n",
        " Use the chosen classification method and let it have a high variance.\n",
        " Train it on the generated features and discuss why it is overfitting.\n",
        "\n",
        " Insert your code here for Task 3\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "TrsSDN_7huYB",
        "outputId": "e0fe786c-94a4-4416-af5e-1f780578aebc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM Fold 1 Accuracy: 0.890625\n",
            "SVM Fold 2 Accuracy: 0.8888888888888888\n",
            "SVM Fold 3 Accuracy: 0.9047619047619048\n",
            "SVM Fold 4 Accuracy: 0.8412698412698413\n",
            "SVM Fold 5 Accuracy: 0.8888888888888888\n",
            "SVM Fold 6 Accuracy: 0.9206349206349206\n",
            "SVM Fold 7 Accuracy: 0.9047619047619048\n",
            "SVM Fold 8 Accuracy: 0.8888888888888888\n",
            "SVM Fold 9 Accuracy: 0.873015873015873\n",
            "SVM Fold 10 Accuracy: 0.9047619047619048\n",
            "Mean SVM Accuracy: 0.8906498015873016\n",
            "SVM Accuracy Variance: 0.0004255200705861044\n"
          ]
        }
      ],
      "source": [
        "# Use a multi-class SVM method to classify data\n",
        "hv_svm_model = svm.SVC(kernel=\"sigmoid\")\n",
        "hv_svm_scores = cross_val_score(hv_svm_model, train_features, train_labels, cv=k)\n",
        "\n",
        "# Print the cross-validation scores\n",
        "for i, hv_score in enumerate(hv_svm_scores):\n",
        "    print(f\"SVM Fold {i+1} Accuracy: {hv_score}\")\n",
        "\n",
        "# Calculate and print the mean accuracy across all folds\n",
        "hv_mean_accuracy = np.mean(hv_svm_scores)\n",
        "print(f\"Mean SVM Accuracy: {hv_mean_accuracy}\")\n",
        "\n",
        "# Calculate and print the accuracy variance across all folds\n",
        "hv_accuracy_var = np.var(hv_svm_scores)\n",
        "print(f\"SVM Accuracy Variance: {hv_accuracy_var}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzxSVPWXht-m"
      },
      "source": [
        " Task 4: Balanced Classification Method (15%)\n",
        " Use the chosen classification method and let it balance the bias and variance.\n",
        " Train it on the generated features, possibly adjusting parameters.\n",
        " Discuss insights into achieving balance.\n",
        "\n",
        " Insert your code here for Task 4\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "hjgmSxk7h7vZ",
        "outputId": "2b37c233-8b9b-47a4-8aa2-ff63dddefc6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM Fold 1 Accuracy: 0.96875\n",
            "SVM Fold 2 Accuracy: 0.9682539682539683\n",
            "SVM Fold 3 Accuracy: 0.9841269841269841\n",
            "SVM Fold 4 Accuracy: 0.9206349206349206\n",
            "SVM Fold 5 Accuracy: 0.9841269841269841\n",
            "SVM Fold 6 Accuracy: 0.9523809523809523\n",
            "SVM Fold 7 Accuracy: 0.9682539682539683\n",
            "SVM Fold 8 Accuracy: 0.9682539682539683\n",
            "SVM Fold 9 Accuracy: 0.9682539682539683\n",
            "SVM Fold 10 Accuracy: 0.9682539682539683\n",
            "Balanced SVM Mean Accuracy: 0.9651289682539682\n",
            "Balanced SVM Accuracy Variance: 0.00029260213923532394\n"
          ]
        }
      ],
      "source": [
        "balanced_svm_model = svm.SVC(kernel=\"linear\")\n",
        "balanced_svm_scores = cross_val_score(\n",
        "    balanced_svm_model, train_features, train_labels, cv=k\n",
        ")\n",
        "\n",
        "# Print the cross-validation scores\n",
        "for i, balanced_score in enumerate(balanced_svm_scores):\n",
        "    print(f\"SVM Fold {i+1} Accuracy: {balanced_score}\")\n",
        "\n",
        "# Calculate and print the mean accuracy across all folds\n",
        "balanced_mean_accuracy = np.mean(balanced_svm_scores)\n",
        "print(f\"Balanced SVM Mean Accuracy: {balanced_mean_accuracy}\")\n",
        "\n",
        "# Calculate and print the accuracy variance across all folds\n",
        "balanced_accuracy_var = np.var(balanced_svm_scores)\n",
        "print(f\"Balanced SVM Accuracy Variance: {balanced_accuracy_var}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKRG3PfFh8Ot"
      },
      "source": [
        " Task 5: K-Means Clustering (20%)\n",
        " Apply K-Means clustering on the generated features.\n",
        " Test with available labels and report accuracy.\n",
        " Experiment with automated K and compare with manually set 20 clusters.\n",
        "\n",
        " Insert your code here for Task 5\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "VLuOkJyAh-mN",
        "outputId": "05037996-6178-470b-cf8c-11a18f765973"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "k = 2: Custom Accuracy = 0.1\n",
            "k = 3: Custom Accuracy = 0.15\n",
            "k = 4: Custom Accuracy = 0.2\n",
            "k = 5: Custom Accuracy = 0.24871794871794872\n",
            "k = 6: Custom Accuracy = 0.2987179487179487\n",
            "k = 7: Custom Accuracy = 0.3487179487179487\n",
            "k = 8: Custom Accuracy = 0.3974358974358974\n",
            "k = 9: Custom Accuracy = 0.4461538461538462\n",
            "k = 10: Custom Accuracy = 0.4948717948717949\n",
            "k = 11: Custom Accuracy = 0.5333333333333333\n",
            "k = 12: Custom Accuracy = 0.5820512820512821\n",
            "k = 13: Custom Accuracy = 0.6256410256410256\n",
            "k = 14: Custom Accuracy = 0.6666666666666666\n",
            "k = 15: Custom Accuracy = 0.7012820512820512\n",
            "k = 16: Custom Accuracy = 0.717948717948718\n",
            "k = 17: Custom Accuracy = 0.7474358974358974\n",
            "k = 18: Custom Accuracy = 0.7884615384615384\n",
            "k = 19: Custom Accuracy = 0.7987179487179488\n",
            "Best custom accuracy: 0.7987179487179488 found for k = 19\n",
            "Custom Accuracy with k = 20: 0.8615384615384616\n",
            "============================================================================================\n",
            "Experimenting with different K values using silhouette_score to find accuracy:\n",
            "For K=2, the average silhouette_score is: 0.16509170830249786\n",
            "For K=3, the average silhouette_score is: 0.16582363843917847\n",
            "For K=4, the average silhouette_score is: 0.12967461347579956\n",
            "For K=5, the average silhouette_score is: 0.0947023257613182\n",
            "For K=6, the average silhouette_score is: 0.10715701431035995\n",
            "For K=7, the average silhouette_score is: 0.14138056337833405\n",
            "For K=8, the average silhouette_score is: 0.15419277548789978\n",
            "For K=9, the average silhouette_score is: 0.16971182823181152\n",
            "For K=10, the average silhouette_score is: 0.17750287055969238\n",
            "For K=11, the average silhouette_score is: 0.18055549263954163\n",
            "For K=12, the average silhouette_score is: 0.19525226950645447\n",
            "For K=13, the average silhouette_score is: 0.18499982357025146\n",
            "For K=14, the average silhouette_score is: 0.19305025041103363\n",
            "For K=15, the average silhouette_score is: 0.19776448607444763\n",
            "For K=16, the average silhouette_score is: 0.18935725092887878\n",
            "For K=17, the average silhouette_score is: 0.18214628100395203\n",
            "For K=18, the average silhouette_score is: 0.18845665454864502\n",
            "For K=19, the average silhouette_score is: 0.1885802000761032\n",
            "For K=20, the average silhouette_score is: 0.17828144133090973\n",
            "For K=21, the average silhouette_score is: 0.17989401519298553\n",
            "For K=22, the average silhouette_score is: 0.17584307491779327\n",
            "For K=23, the average silhouette_score is: 0.17139911651611328\n",
            "For K=24, the average silhouette_score is: 0.17576125264167786\n",
            "For K=25, the average silhouette_score is: 0.1765284240245819\n",
            "For K=26, the average silhouette_score is: 0.17592550814151764\n",
            "For K=27, the average silhouette_score is: 0.17190589010715485\n",
            "For K=28, the average silhouette_score is: 0.1730881780385971\n",
            "For K=29, the average silhouette_score is: 0.16466635465621948\n",
            "For K=30, the average silhouette_score is: 0.16009651124477386\n",
            "The best K is 15 with an average silhouette score of 0.19776448607444763.\n",
            "Custom Accuracy with best silhouette score (k = 15): 0.7012820512820512\n"
          ]
        }
      ],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score, accuracy_score\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "# Load features and labels from Numpy files.\n",
        "train_features = np.load(\"train_features.npy\")\n",
        "train_labels = np.load(\"train_labels.npy\")\n",
        "val_features = np.load(\"val_features.npy\")\n",
        "val_labels = np.load(\"val_labels.npy\")\n",
        "test_features = np.load(\"test_features.npy\")\n",
        "test_labels = np.load(\"test_labels.npy\")\n",
        "\n",
        "# Combine features and labels from training, validation, and test sets for clustering analysis.\n",
        "features = np.concatenate((train_features, val_features, test_features), axis=0)\n",
        "labels = np.concatenate((train_labels, val_labels, test_labels), axis=0)\n",
        "\n",
        "\n",
        "def calculate_custom_accuracy(clusters, true_labels):\n",
        "    \"\"\"\n",
        "    Calculate the custom accuracy for clustering by assigning the most frequent true label\n",
        "    to each cluster and then comparing these assigned labels to the true labels.\n",
        "\n",
        "    Parameters:\n",
        "    - clusters (numpy.ndarray): Cluster assignments for each data point.\n",
        "    - true_labels (numpy.ndarray): True labels for each data point.\n",
        "\n",
        "    Returns:\n",
        "    - float: The accuracy of the clustering based on how well the assigned cluster labels\n",
        "             match the true labels.\n",
        "    \"\"\"\n",
        "    label_mapping = {}\n",
        "    for cluster_id in set(clusters):\n",
        "        # Identify all data points assigned to the current cluster.\n",
        "        cluster_indices = np.where(clusters == cluster_id)[0]\n",
        "        # Get the true labels of these data points.\n",
        "        cluster_labels = true_labels[cluster_indices]\n",
        "        # Determine the most common label in the cluster.\n",
        "        most_common_label = Counter(cluster_labels).most_common(1)[0][0]\n",
        "        # Assign this label to the cluster.\n",
        "        label_mapping[cluster_id] = most_common_label\n",
        "    # Create an array of predicted labels based on the cluster assignments.\n",
        "    predicted_labels = np.array([label_mapping[cluster_id] for cluster_id in clusters])\n",
        "    # Calculate and return the accuracy.\n",
        "    return accuracy_score(true_labels, predicted_labels)\n",
        "\n",
        "\n",
        "# Initialize variables to track the best number of clusters (k) and the highest accuracy found.\n",
        "best_k = 2\n",
        "best_accuracy = 0\n",
        "\n",
        "# Iterate over a range of k values to find the best one based on custom accuracy.\n",
        "for k in range(2, 20):\n",
        "    # Perform KMeans clustering with the current value of k.\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=\"auto\").fit(features)\n",
        "    # Get the cluster assignments for each data point.\n",
        "    clusters = kmeans.labels_\n",
        "    # Calculate the custom accuracy for these cluster assignments.\n",
        "    accuracy = calculate_custom_accuracy(clusters, labels)\n",
        "    print(f\"k = {k}: Custom Accuracy = {accuracy}\")\n",
        "    # Update the best k and accuracy if the current accuracy is higher.\n",
        "    if accuracy > best_accuracy:\n",
        "        best_accuracy = accuracy\n",
        "        best_k = k\n",
        "\n",
        "# Report the best custom accuracy found and the corresponding value of k.\n",
        "print(f\"Best custom accuracy: {best_accuracy} found for k = {best_k}\")\n",
        "\n",
        "# Perform clustering again with k set to 20 for comparison.\n",
        "kmeans_20 = KMeans(n_clusters=31, random_state=42, n_init=\"auto\").fit(features)\n",
        "clusters_20 = kmeans_20.labels_\n",
        "# Calculate and print the custom accuracy for k=20.\n",
        "accuracy_20 = calculate_custom_accuracy(clusters_20, labels)\n",
        "print(f\"Custom Accuracy with k = 20: {accuracy_20}\")\n",
        "\n",
        "\n",
        "# Assuming 'features' contains your data\n",
        "features = np.concatenate((train_features, val_features, test_features), axis=0)\n",
        "\n",
        "# Define the range of K to try\n",
        "k_values = range(2, 31)  # Example: trying values of K from 2 to 30\n",
        "\n",
        "best_k = None\n",
        "best_silhouette = -1\n",
        "print(\n",
        "    \"============================================================================================\"\n",
        ")\n",
        "# Experiment with different K values\n",
        "print(\"Experimenting with different K values using silhouette_score to find accuracy:\")\n",
        "for k in k_values:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=\"auto\").fit(features)\n",
        "    cluster_labels = kmeans.labels_\n",
        "    silhouette_avg = silhouette_score(features, cluster_labels)\n",
        "\n",
        "    print(f\"For K={k}, the average silhouette_score is: {silhouette_avg}\")\n",
        "\n",
        "    # Update the best K if the current silhouette score is better\n",
        "    if silhouette_avg > best_silhouette:\n",
        "        best_k = k\n",
        "        best_silhouette = silhouette_avg\n",
        "\n",
        "# After finding the best_k based on silhouette scores\n",
        "print(f\"The best K is {best_k} with an average silhouette score of {best_silhouette}.\")\n",
        "\n",
        "# Perform KMeans clustering again using the best_k found from silhouette scores\n",
        "kmeans_best_silhouette = KMeans(n_clusters=best_k, random_state=42, n_init=\"auto\").fit(\n",
        "    features\n",
        ")\n",
        "clusters_best_silhouette = kmeans_best_silhouette.labels_\n",
        "\n",
        "# Calculate and print the custom accuracy for the clustering with best silhouette score\n",
        "accuracy_best_silhouette = calculate_custom_accuracy(clusters_best_silhouette, labels)\n",
        "print(\n",
        "    f\"Custom Accuracy with best silhouette score (k = {best_k}): {accuracy_best_silhouette}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43sPfI7Jh-9p"
      },
      "source": [
        " Task 6: Additional Clustering Algorithm (10%)\n",
        " Choose another clustering algorithm and apply it on the features.\n",
        " Test accuracy with available labels.\n",
        "\n",
        " Insert your code here for Task 6\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "Nn9f41LWiCDr",
        "outputId": "361aeaba-9d78-43ba-84bc-91d0be613686"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eps = 3, min_samples = 5: Custom Accuracy = 0\n",
            "eps = 3, min_samples = 10: Custom Accuracy = 0\n",
            "eps = 3, min_samples = 15: Custom Accuracy = 0\n",
            "eps = 5, min_samples = 5: Custom Accuracy = 0\n",
            "eps = 5, min_samples = 10: Custom Accuracy = 0\n",
            "eps = 5, min_samples = 15: Custom Accuracy = 0\n",
            "eps = 7, min_samples = 5: Custom Accuracy = 0\n",
            "eps = 7, min_samples = 10: Custom Accuracy = 0\n",
            "eps = 7, min_samples = 15: Custom Accuracy = 0\n",
            "eps = 10, min_samples = 5: Custom Accuracy = 0.6174242424242424\n",
            "eps = 10, min_samples = 10: Custom Accuracy = 0.7251184834123223\n",
            "eps = 10, min_samples = 15: Custom Accuracy = 0.7151162790697675\n",
            "Best custom accuracy: 0.7251184834123223 found for eps = 10 and min_samples = 10\n"
          ]
        }
      ],
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.metrics import silhouette_score, accuracy_score\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "# Load features and labels from Numpy files.\n",
        "train_features = np.load(\"train_features.npy\")\n",
        "train_labels = np.load(\"train_labels.npy\")\n",
        "val_features = np.load(\"val_features.npy\")\n",
        "val_labels = np.load(\"val_labels.npy\")\n",
        "test_features = np.load(\"test_features.npy\")\n",
        "test_labels = np.load(\"test_labels.npy\")\n",
        "\n",
        "# Combine features and labels from training, validation, and test sets for clustering analysis.\n",
        "features = np.concatenate((train_features, val_features, test_features), axis=0)\n",
        "labels = np.concatenate((train_labels, val_labels, test_labels), axis=0)\n",
        "\n",
        "# Your existing custom accuracy function should work fine here as well.\n",
        "\n",
        "\n",
        "# Explore a range of values for eps and min_samples to find the best DBSCAN configuration.\n",
        "eps_values = [\n",
        "    3,\n",
        "    5,\n",
        "    7,\n",
        "    10,\n",
        "]  # Example eps values. You should adjust this based on your data.\n",
        "min_samples_values = [5, 10, 15]  # Example min_samples values.\n",
        "\n",
        "best_eps = None\n",
        "best_min_samples = None\n",
        "best_accuracy = 0\n",
        "\n",
        "\n",
        "def calculate_custom_accuracy(clusters, true_labels):\n",
        "    # Filter out noise (-1 labels) from the clusters and corresponding true labels\n",
        "    valid_indices = clusters != -1\n",
        "    if not np.any(\n",
        "        valid_indices\n",
        "    ):  # If all points are noise, return 0 accuracy or an appropriate value\n",
        "        return 0\n",
        "    filtered_clusters = clusters[valid_indices]\n",
        "    filtered_labels = true_labels[valid_indices]\n",
        "\n",
        "    label_mapping = {}\n",
        "    for cluster_id in set(filtered_clusters):\n",
        "        cluster_indices = np.where(filtered_clusters == cluster_id)[0]\n",
        "        cluster_labels = filtered_labels[cluster_indices]\n",
        "        if (\n",
        "            cluster_labels.size == 0\n",
        "        ):  # Skip if the cluster is empty (should not happen after filtering noise)\n",
        "            continue\n",
        "        most_common_label = Counter(cluster_labels).most_common(1)[0][0]\n",
        "        label_mapping[cluster_id] = most_common_label\n",
        "\n",
        "    predicted_labels = np.array(\n",
        "        [label_mapping.get(cluster_id, -1) for cluster_id in filtered_clusters]\n",
        "    )\n",
        "    return accuracy_score(filtered_labels, predicted_labels)\n",
        "\n",
        "\n",
        "for eps in eps_values:\n",
        "    for min_samples in min_samples_values:\n",
        "        # Perform DBSCAN clustering with the current value of eps and min_samples.\n",
        "        dbscan = DBSCAN(eps=eps, min_samples=min_samples).fit(features)\n",
        "        # DBSCAN labels_ attribute to get the cluster assignments.\n",
        "        clusters = dbscan.labels_\n",
        "\n",
        "        # Ignore noise points (cluster label = -1) in accuracy calculation if necessary\n",
        "        if np.any(clusters == -1):\n",
        "            # Optional: Filter out noise points for accuracy calculation\n",
        "            valid_indices = clusters != -1\n",
        "            filtered_clusters = clusters[valid_indices]\n",
        "            filtered_labels = labels[valid_indices]\n",
        "            accuracy = calculate_custom_accuracy(filtered_clusters, filtered_labels)\n",
        "        else:\n",
        "            accuracy = calculate_custom_accuracy(clusters, labels)\n",
        "\n",
        "        print(f\"eps = {eps}, min_samples = {min_samples}: Custom Accuracy = {accuracy}\")\n",
        "\n",
        "        # Update the best eps, min_samples, and accuracy if the current accuracy is higher.\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            best_eps = eps\n",
        "            best_min_samples = min_samples\n",
        "\n",
        "# Report the best custom accuracy found and the corresponding values of eps and min_samples.\n",
        "print(\n",
        "    f\"Best custom accuracy: {best_accuracy} found for eps = {best_eps} and min_samples = {best_min_samples}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fPfoBsaiCXu"
      },
      "source": [
        " Task 7: PCA for Classification Improvement (20%)\n",
        " Apply PCA on the features and then feed them to the best classification method in the above tasks.\n",
        " Assess if PCA improves outcomes and discuss the results.\n",
        "\n",
        " Insert your code here for Task 7\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "RoOFXhdmiHeD"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (3008200728.py, line 21)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;36m  Cell \u001b[1;32mIn[69], line 21\u001b[1;36m\u001b[0m\n\u001b[1;33m    [[RUN BEST OTHER MODEL]]\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "Data_To_PCA = [[placeholder]]\n",
        "\n",
        "# project from X to K dimensions using PCA\n",
        "k = 2\n",
        "\n",
        "# using sklearn's implementation\n",
        "pca = PCA(k)\n",
        "projected_sklearn = pca.fit_transform(Data_To_PCA.data)\n",
        "print('reduced dim (sklearn):', projected_sklearn.shape)\n",
        "plt.figure(1,figsize = (12,4))\n",
        "\n",
        "plt.scatter(projected_sklearn[:, 0], projected_sklearn[:, 1],\n",
        "            c=Data_To_PCA.target, edgecolor='none', alpha=0.5,\n",
        "            cmap=plt.cm.get_cmap('tab20', 10))\n",
        "plt.xlabel('component 1')\n",
        "plt.ylabel('component 2')\n",
        "plt.title('Dim reduction using PCA (sklearn)')\n",
        "plt.colorbar()\n",
        "\n",
        "\n",
        "[[RUN BEST OTHER MODEL]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQqNra7eiHx-"
      },
      "source": [
        " Task 8: Visualization and Analysis (10%)\n",
        " Plot the features in a lower dimension using dimentinality reduction techniques.\n",
        " Analyze the visual representation, identifying patterns or insights.\n",
        "\n",
        "Insert your code here for Task 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1npTL_NkjNdL"
      },
      "outputs": [],
      "source": [
        "import umap\n",
        "Data_To_Reduce = [[placeholder]]\n",
        "Labels_For_Reduction = [[placeholder]]\n",
        "mapper = umap.UMAP().fit(Data_To_Reduce)\n",
        "umap.plot.points(mapper,labels=Labels_For_Reduction,theme='fire')\n",
        "\n",
        "\n",
        "umap.plot.output_notebook()\n",
        "hover_data = pd.DataFrame({'index':np.arange(30000),\n",
        "                           'label':Labels_For_Reduction})\n",
        "hover_data['item'] = hover_data.label.map(\n",
        "    {\n",
        "        '0':'Name1',\n",
        "        '1':'Name1',\n",
        "        '2':'Name1',\n",
        "        '3':'Name1',\n",
        "        '4':'Name1',\n",
        "        '5':'Name1',\n",
        "        '6':'Name1',\n",
        "        '7':'Name1',\n",
        "        '8':'Name1',\n",
        "        '9':'Name1',\n",
        "    }\n",
        ")\n",
        "p = umap.plot.interactive(mapper, labels=Labels_For_Reduction, hover_data=hover_data, point_size=2)\n",
        "umap.plot.show(p)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
