{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cpu\n","Train size: 8000, Validation size: 2000\n","Train dataset size: 8000\n","Validation dataset size: 2000\n"]}],"source":["\n","import torch\n","from torch import nn\n","from icecream import ic\n","from torch.optim import Adam\n","from torchinfo import summary\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","from torch.utils.data import Subset\n","from torch.optim import lr_scheduler\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader, TensorDataset, random_split\n","\n","\n","# -------------------------------------------------------\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(str(device))\n","\n","N = 4  # number of images in whole picture\n","L_x = 5  # x and y pixel dims\n","L_y = 5\n","N_i = L_x * L_y\n","N_h = 256  # number of hidden units\n","N_o = 1  # number of output units\n","\n","\n","class IonImagesDataset(Dataset):\n","    def __init__(self, file_path):\n","        loaded_data_dict = torch.load(file_path)  # loading dataset into dataloader\n","\n","        self.images = loaded_data_dict[\n","            \"images\"\n","        ]  # creating of 2 datasents of imgages and keys to them\n","        self.labels = loaded_data_dict[\"labels\"]\n","\n","    def __len__(self):\n","        return len(self.images)  # just return len function\n","\n","    def __getitem__(self, idx):\n","        image_tensor = self.images[idx]  # Add a channel dimension\n","        label_tensor = self.labels[idx]  # Repeat the label for each ion position\n","        return image_tensor, label_tensor\n","\n","\n","file_path_pt = \"binary\\labels_and_images.pt\"\n","\n","\n","dataset = IonImagesDataset(file_path_pt)\n","halfpi_dataset = IonImagesDataset(file_path_pt)\n","\n","# Split the dataset into training and validation subsets\n","train_size = int(0.8 * len(dataset))\n","val_size = len(dataset) - train_size\n","print(\n","    f\"Train size: {train_size}, Validation size: {val_size}\"\n",")  # Print the sizes of subsets\n","\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","print(\n","    f\"Train dataset size: {len(train_dataset)}\"\n",")  # Print the size of the train_dataset\n","print(\n","    f\"Validation dataset size: {len(val_dataset)}\"\n",")  # Print the size of the val_dataset\n","\n","# Create DataLoaders for the training and validation datasets\n","batch_size = min(1000, len(train_dataset))  # or choose a smaller value\n","train_loader = DataLoader(\n","    train_dataset, batch_size=batch_size, shuffle=True, drop_last=False\n",")\n","val_loader = DataLoader(\n","    val_dataset, batch_size=batch_size, shuffle=True, drop_last=False\n",")\n","\n","halfpi_loader = DataLoader(\n","    halfpi_dataset, batch_size=batch_size, shuffle=True, drop_last=False\n",")\n","\n","\n","class IndexDependentDense(nn.Module):\n","    def __init__(self, N, N_i, N_o, activation=nn.ReLU()):\n","        super().__init__()\n","\n","        self.N = N\n","        self.N_i = N_i\n","        self.N_o = N_o\n","        self.activation = activation\n","        self.register_parameter(\n","            \"W\", nn.Parameter(torch.empty(self.N, self.N_i, self.N_o))\n","        )\n","        self.register_parameter(\"b\", nn.Parameter(torch.empty(self.N, self.N_o)))\n","\n","        self._reset_parameters()\n","\n","        pass\n","\n","    def _reset_parameters(self):\n","        nn.init.xavier_uniform_(self.W)\n","        nn.init.zeros_(self.b)\n","\n","    def forward(self, x):\n","        y = torch.einsum(\"nij,...ni->...nj\", self.W, x) + self.b\n","        if self.activation is not None:\n","            return self.activation(y)\n","        else:\n","            return y\n","\n","    pass\n","\n","\n","# ---------------------------------------------------------------------------------------------\n","\n","\n","class Encoder(nn.Module):\n","    def __init__(self, N, N_i, N_o):\n","        super().__init__()\n","\n","        self.N = N\n","        self.N_i = N_i\n","        self.N_o = N_o\n","\n","        self.dense = IndexDependentDense(N, N_i, N_o, activation=nn.ReLU())\n","        pass\n","\n","    def forward(self, x):\n","        y = self.dense(x)\n","        return y\n","\n","    pass\n","\n","\n","# ---------------------------------------------------------------------------------------------\n","\n","\n","class Classifier(nn.Module):\n","    def __init__(self, N, N_i, N_o):\n","        super().__init__()\n","\n","        self.N = N\n","        self.N_i = N_i\n","        self.N_o = N_o\n","        self.dense = IndexDependentDense(N, N_i, N_o, activation=None)\n","        pass\n","\n","    def forward(self, x):\n","        y = self.dense(x)\n","        y = torch.sigmoid(y)  # Apply sigmoid activation here\n","        return y\n","\n","    pass\n","\n","\n","# ---------------------------------------------------------------------------------------------\n","\n","\n","class SharedEncoder(nn.Module):\n","    def __init__(self, N, N_i, N_o):\n","        super().__init__()\n","\n","        self.N = N\n","        self.N_i = N_i\n","        self.N_o = N_o\n","\n","        self.dense = nn.Linear(N_i, N_o)\n","        pass\n","\n","    def forward(self, x):\n","        y = self.dense(x)\n","        return y\n","\n","    pass\n","\n","\n","# ---------------------------------------------------------------------------------------------\n","\n","\n","class MultiIonReadout(nn.Module):\n","    def __init__(self, encoder, shared_encoder, classifier):\n","        super().__init__()\n","\n","        self.encoder = encoder\n","        self.shared_encoder = shared_encoder\n","        self.classifier = classifier\n","\n","    def forward(self, x):\n","        y = x.reshape(*x.shape[:-2], -1).to(torch.float32)\n","        y1 = self.encoder(y)\n","        y2 = self.shared_encoder(y)\n","        y_concat = torch.cat([y1, y2], dim=-1)\n","        y = self.classifier(y_concat)\n","        return y\n","\n","    def bceloss(self, X, y):\n","        return F.binary_cross_entropy(self(X), y)\n","\n","    @staticmethod\n","    def _accuracy(y_pred, y_true):\n","        mod_y_pred = (y_pred > 0.5).to(torch.float32)\n","        accuracy = (y_true == mod_y_pred).to(dtype=torch.float32).mean()\n","        return accuracy * 100\n","\n","    def accuracy(self, x, y):\n","        return self._accuracy(self(x), y)\n","\n","\n","# ---------------------------------------------------------------------------------------------"]},{"cell_type":"code","execution_count":2,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["35332\n","35332\n"," Epoch 100/100, Training Loss = 0.2069842368364334, Val Loss = 0.22685407102108002, Val Acc = 91.86249923706055"]}],"source":["device = torch.device(\"cpu\")\n","# model \n","encoder = Encoder(N, N_i, N_h)\n","shared_encoder = SharedEncoder(N, N_i, N_h)\n","classifier = Classifier(N, N_h * 2, N_o)\n","model = MultiIonReadout(encoder, shared_encoder, classifier)\n","\n","\n","model = model.to(device)\n","pytorch_total_params = sum(p.numel() for p in model.parameters())\n","pytorch_total_params2 = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","print(pytorch_total_params)\n","print(pytorch_total_params2)\n","\n","N_epochs = 100\n","lr = 1e-3\n","optimizer = Adam(model.parameters(), lr=lr)\n","schedule_params = {\"factor\": 1}\n","schedule = lr_scheduler.ConstantLR(optimizer, **schedule_params)\n","log_every = 1\n","\n","# Training loop\n","for epoch in range(N_epochs):\n","\n","    total_train_loss = 0\n","    for inputs, labels in train_loader:\n","\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        loss = model.bceloss(inputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","    # Evaluation loop\n","    with torch.no_grad():\n","        total_loss = 0\n","        total_accuracy = 0\n","        for inputs, labels in val_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            loss = model.bceloss(inputs, labels)\n","            accuracy = model.accuracy(inputs, labels)\n","            total_loss += loss.item()\n","            total_accuracy += accuracy.item()\n","\n","        avg_loss = total_loss / len(val_loader)\n","        avg_accuracy = total_accuracy / len(val_loader)\n","\n","    print(\n","        \"\\r Epoch {}/{}, Training Loss = {}, Val Loss = {}, Val Acc = {}\".format(\n","            epoch + 1, N_epochs, loss.item(), avg_loss, avg_accuracy\n","        ),\n","        end=\"\",\n","    )\n","\n","# torch.save(model.state_dict(), \"golden_WandB_n.pth\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":4}
